{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT微调.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBP4tuKE8OCL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ab3518c6-6d66-4068-84a1-ab0fc96d448d"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    device = 'cuda'\n",
        "else:\n",
        "\n",
        "    device = 'cpu'\n",
        "    \n",
        "print(device)\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name())"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "1\n",
            "Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_3l4dvDmDto",
        "colab_type": "code",
        "outputId": "6297f0ac-9761-483f-8807-e9087b4dea11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUzxbGiMmKe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import BertModel, BertTokenizer, BertForSequenceClassification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0VwUd2TmeL-",
        "colab_type": "code",
        "outputId": "3495742c-7e77-43c8-cba7-ccb2e3a7e4e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmLm3zuLmmqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wget\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTFAXOT4moxp",
        "colab_type": "code",
        "outputId": "72cc16fb-8e41-4362-f571-83aafc4435ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/theneuralbeing/bert-finetuning-webinar/master/data.zip'\n",
        "print('DownLoading Dataset')\n",
        "if not os.path.exists('./data.zip'):\n",
        "    wget.download(url,'./data.zip')\n",
        "    !unzip data.zip\n",
        "    print('Unzipped')"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DownLoading Dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1hD-Qevnujq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLWO0apnn96G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('./data/train.csv',delimiter = ',',header = None, names = ['review','sentiment'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F8bHZh5oaIc",
        "colab_type": "code",
        "outputId": "de851dae-cbfe-4228-dbec-fb370a38e578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('Number of training sentence:{}\\n'.format(df.shape[0]))   \n",
        "print('Number of labels:{}\\n'.format(df.shape[1]))"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentence:25001\n",
            "\n",
            "Number of labels:2\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b88XMcrNzmZt",
        "colab_type": "code",
        "outputId": "8495c38d-bc5e-46ee-d856-d36a27dab08f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df1 = pd.read_csv('./data/validation.csv',delimiter = ',',header = None, names = ['review','sentiment'])\n",
        "print('Number of training sentence:{}\\n'.format(df1.shape[0]))   \n",
        "print('Number of labels:{}\\n'.format(df1.shape[1]))"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentence:25001\n",
            "\n",
            "Number of labels:2\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOYu1R_80RgZ",
        "colab_type": "code",
        "outputId": "455dca5f-0d75-45f5-fc76-4850c86dd73b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "df1.sample(10)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6189</th>\n",
              "      <td>Do NOT judge this production by the 2-hour ver...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21872</th>\n",
              "      <td>Watching Stranger Than Fiction director Marc F...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5726</th>\n",
              "      <td>It's been a long time since I last saw a movie...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12258</th>\n",
              "      <td>Please humour me if you will, for a minute whi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7069</th>\n",
              "      <td>This has to be the worst movie i've seen this ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7651</th>\n",
              "      <td>Now this is one of Big's Best, Jack Hulbert's ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11406</th>\n",
              "      <td>It says a lot about the United Kingdom when te...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13623</th>\n",
              "      <td>I play this game exactly after I watch the tra...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7655</th>\n",
              "      <td>Pokemon 3 is little more than three or four ep...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19274</th>\n",
              "      <td>an oirish film not made for an irish audience....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "6189   Do NOT judge this production by the 2-hour ver...         1\n",
              "21872  Watching Stranger Than Fiction director Marc F...         1\n",
              "5726   It's been a long time since I last saw a movie...         0\n",
              "12258  Please humour me if you will, for a minute whi...         0\n",
              "7069   This has to be the worst movie i've seen this ...         0\n",
              "7651   Now this is one of Big's Best, Jack Hulbert's ...         1\n",
              "11406  It says a lot about the United Kingdom when te...         0\n",
              "13623  I play this game exactly after I watch the tra...         1\n",
              "7655   Pokemon 3 is little more than three or four ep...         0\n",
              "19274  an oirish film not made for an irish audience....         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93ud8D6N-Amj",
        "colab_type": "text"
      },
      "source": [
        "对数据进行可视化分析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPXx5RcC-Nlz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "d467fb60-bb70-4dbb-db94-0b3e5a0d3a5d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "df['sentiment'].value_counts().plot.bar()\n",
        "plt.title(\"Sentiment Analysis\")\n",
        "df['sentiment'].value_counts(normalize = True)"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0            0.50102\n",
              "1            0.49894\n",
              "sentiment    0.00004\n",
              "Name: sentiment, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAExCAYAAACeZs5sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKp1ZHEp_cCs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d33d9cec-c7f8-407c-a96e-eb2395c90eec"
      },
      "source": [
        "import seaborn as sns\n",
        "df['review_'] = df['review'].astype(str).apply(len)\n",
        "sns.kdeplot(df['review_'])"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f323173f860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD4CAYAAADo30HgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB6glpx8uAUWdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0j3z_aeAw3E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "2b5a00e2-0276-43c2-8e9d-2bc50aeac419"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25001 entries, 0 to 25000\n",
            "Data columns (total 3 columns):\n",
            "review       25001 non-null object\n",
            "sentiment    25001 non-null object\n",
            "review_      25001 non-null int64\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 586.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeOMrW4Koy0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrbSg0wrCfEi",
        "colab_type": "text"
      },
      "source": [
        "加载数据并对数据预处理\n",
        "1.读数据\n",
        "2.切分句子\n",
        "3.填充（pad）\n",
        "4.转ID\n",
        "5.转tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwyU7LMWqbrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LoadDataset(Dataset):\n",
        "\n",
        "    def __init__(self,filename,maxlen): \n",
        "\n",
        "        self.df = pd.read_csv(filename,delimiter = ',')\n",
        "\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        \n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "\n",
        "      sentence = self.df.loc[index,'review'] \n",
        "\n",
        "      label = self.df.loc[index,'sentiment']\n",
        "\n",
        "      tokens = self.tokenizer.tokenize(sentence)\n",
        "\n",
        "      tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "\n",
        "      #print(tokens)\n",
        "      if len(tokens) < self.maxlen:\n",
        "\n",
        "          tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))]\n",
        "\n",
        "      else:\n",
        "\n",
        "          tokens = tokens[:self.maxlen -1] + ['[PAD]']\n",
        "\n",
        "      #print(tokens)\n",
        "\n",
        "      tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "      #print(tokens_ids)\n",
        "\n",
        "      tokens_ids_tensor = torch.tensor(tokens_ids)\n",
        "      #print(tokens_ids_tensor)\n",
        "\n",
        "      attn_mask = (tokens_ids_tensor != 0).long()\n",
        "\n",
        "      return tokens_ids_tensor, attn_mask, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGTACZ7EDCkj",
        "colab_type": "text"
      },
      "source": [
        "实例化训练集和验证集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnWhGOL9ye-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = LoadDataset(filename = 'data/train.csv',maxlen = 64)\n",
        "\n",
        "val_set = LoadDataset(filename = 'data/validation.csv',maxlen = 64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dgp5D_ODboC",
        "colab_type": "text"
      },
      "source": [
        "把数据集按batch_size大小分成n等份个迭代"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0JaYJxzy6_e",
        "colab_type": "code",
        "outputId": "e6a6761e-59cd-40e6-93d5-e4259dc35000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_loader = DataLoader(train_set,batch_size = 32,num_workers = 5)\n",
        "\n",
        "val_loader = DataLoader(val_set,batch_size = 32, num_workers = 5)\n",
        "\n",
        "print(len(train_loader))\n",
        "print(len(val_loader))"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782\n",
            "782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HAkyYaJEp0j",
        "colab_type": "text"
      },
      "source": [
        "情感分类模型设计"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb6AyNrtzu9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Plfgz5Saz2K-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentClassifier(nn.Module): \n",
        "\n",
        "    def __init__(self,freeze_bert = True):\n",
        "\n",
        "        super(SentimentClassifier,self).__init__()\n",
        "\n",
        "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        self.classifier = nn.Linear(768,1)\n",
        "\n",
        "    def forward(self,seq,attn_masks): \n",
        "\n",
        "        cont_reps,_ = self.bert_layer(seq,attention_mask = attn_masks) #把处理好的数据放入bert中以得到特征表示，大小为[32,64,768]\n",
        "\n",
        "        cls_rep = cont_reps[:,0]   #取[CLS]也即第一个，大小为[32,768]\n",
        "\n",
        "        logits = self.classifier(cls_rep) #把[CLS]做一个连接，大小为[32,1]\n",
        "\n",
        "        return logits                  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwETpWqg1sOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SentimentClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mb_BBvpkHBvg",
        "colab_type": "text"
      },
      "source": [
        "为训练准备损失函数和优化器：\n",
        "1.训练是损失函数用BCEWithLogtsLoss、优化器用Adam\n",
        "2.验证是优化器也用Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjZQ6n2A2XSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim import Adam\n",
        "from torch.nn import BCEWithLogitsLoss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCH5xSbv2rrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = BCEWithLogitsLoss()\n",
        "\n",
        "optimizer = Adam(model.parameters(),lr = 2e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF9ChHYRhq7f",
        "colab_type": "code",
        "outputId": "e8eaaf5a-3864-4cef-99b4-021ee454bc48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "\n",
        "    device = 'cuda'\n",
        "\n",
        "else:\n",
        "  \n",
        "    device = 'cpu'\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jamaZ1LS8z5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTVTDcnNgiu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logits_accuracy(logits,labels):\n",
        "\n",
        "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
        "\n",
        "    #print(\"probs shape:\",probs.shape)\n",
        "    preds = (probs > 0.5).long() \n",
        "\n",
        "    #print(\"preds shape:\",preds.shape)\n",
        "    #print(\"preds.squeeze shape:\",preds.squeeze().shape)\n",
        "    acc = (preds.squeeze() == labels).float().mean()\n",
        "    \n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x49TT9XweKKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(net,criterion,val_loader,device):\n",
        "\n",
        "    losses ,accuracies = 0,0\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    count = 0         #count用来计数（迭代数）用于后面对损失和准确率做平均\n",
        "\n",
        "    for (seq,attn_masks,labels) in val_loader:\n",
        "\n",
        "        count += 1    \n",
        "\n",
        "        seq,attn_masks,labels = seq.to(device),attn_masks.to(device),labels.to(device)\n",
        "\n",
        "        val_logits = net(seq,attn_masks)\n",
        "\n",
        "        val_loss = criterion(val_logits.squeeze(-1),labels.float())\n",
        "\n",
        "        losses += val_loss.item()   #累加所有迭代的损失\n",
        "        \n",
        "        accuracies += logits_accuracy(val_logits,labels)    \n",
        "\n",
        "        return losses / count , accuracies / count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrLKwgOG3Ai8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net,criterion,optimizer,train_loader,val_loader,device,epochs = 4 ,print_every = 100):\n",
        "\n",
        "    net.to(device)  #给模型配置GPU/CPU\n",
        "\n",
        "    net.train()   \n",
        "\n",
        "    print('========================START TRAINING=================================')\n",
        "\n",
        "    for epoch in range(epochs):   \n",
        "\n",
        "        print('=======================EPOCH :{}'.format(epoch))\n",
        "\n",
        "        t1 = time()   #一个epoch的开始时间\n",
        "\n",
        "        for i , (seq,attn_masks,labels) in enumerate(train_loader):  #i用于打印多少次迭代\n",
        "\n",
        "            optimizer.zero_grad() \n",
        "\n",
        "            seq, attn_masks, labels = seq.to(device),attn_masks.to(device),labels.to(device)  #给数据配置GPU/CPU\n",
        "\n",
        "            logits = net(seq,attn_masks)  #[32,1]\n",
        "\n",
        "            loss = criterion(logits.squeeze(-1),labels.float())\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            nn.utils.clip_grad_norm_(net.parameters(),1)  #防止梯度爆炸\n",
        "\n",
        "            optimizer.step()  #反向传播后更新模型参数\n",
        "\n",
        "            if (i+1) % print_every == 0:\n",
        "\n",
        "                print('\\n\\nIteratiom:{}\\nLoss:{}'.format(i+1,loss.item())) #每训练完100个迭代打印此时的损失\n",
        "\n",
        "        t2 = time()       #一个epoch的结束时间\n",
        "\n",
        "        print('Taken time for EPOCH:{}'.format(t2-t1))\n",
        "\n",
        "        print('\\n======================Validating=================')\n",
        "\n",
        "        mean_val_loss, mean_val_acc = evaluate(net,criterion,val_loader,device) #每训练完一个epoch，算损失和准确率\n",
        "\n",
        "        print('Validation Loss:{}\\nValidation Accuracy:{}'.format(mean_val_loss,mean_val_acc)) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVzdqFC1Br7y",
        "colab_type": "code",
        "outputId": "a7e34f83-2b4f-4ef1-cb9b-323d3fbc2c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "train(model,criterion,optimizer,train_loader,val_loader,device,epochs = 1,print_every = 100)"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========================START TRAINING=================================\n",
            "=======================EPOCH :0\n",
            "\n",
            "\n",
            "Iteratiom:100\n",
            "Loss:0.4208635091781616\n",
            "\n",
            "\n",
            "Iteratiom:200\n",
            "Loss:0.6658065319061279\n",
            "\n",
            "\n",
            "Iteratiom:300\n",
            "Loss:0.400304913520813\n",
            "\n",
            "\n",
            "Iteratiom:400\n",
            "Loss:0.43304798007011414\n",
            "\n",
            "\n",
            "Iteratiom:500\n",
            "Loss:0.3171434998512268\n",
            "\n",
            "\n",
            "Iteratiom:600\n",
            "Loss:0.3901852071285248\n",
            "\n",
            "\n",
            "Iteratiom:700\n",
            "Loss:0.39116454124450684\n",
            "Taken time for EPOCH:534.2826356887817\n",
            "\n",
            "======================Validating=================\n",
            "Validation Loss:0.3435032367706299\n",
            "Validation Accuracy:0.875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7RQM06MQu1Z",
        "colab_type": "text"
      },
      "source": [
        "存储模型参数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZvZN4iTQDt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkSRFxV2QLAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isdir('./save_path'):\n",
        "\n",
        "    os.mkdir('./save_path')\n",
        "\n",
        "torch.save({\n",
        "    \n",
        "    'model_state_dict': model.state_dict(),\n",
        "\n",
        "    'optimizer_state_dict':optimizer.state_dict()\n",
        "    \n",
        "},'save_path/model.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMKSAaaQSK3q",
        "colab_type": "text"
      },
      "source": [
        "保存整个网络:torch.save(net, PATH) \n",
        "保存网络中的参数, 速度快，占空间少:torch.save(net.state_dict(),PATH)\n",
        "针对上面一般的保存方法，加载的方法分别是：\n",
        "model_dict=torch.load(PATH)\n",
        "model_dict=model.load_state_dict(torch.load(PATH))\n",
        "详见https://zhuanlan.zhihu.com/p/38056115"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lffxIzNNQ8s0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #model.state_dict().items()\n",
        " #optimizer.state_dict().items()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMumF4dtSmyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checkpoint = torch.load('save_path/model.pth')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkBO7sLoTtL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHIU-SPMT1Xz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.load_state_dict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IycOyRsUzSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inference_file = torch.load('save_path/model.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9q_9qhmr4fm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictor = SentimentClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYhW4thGsHjV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0a5263de-03e3-48cf-d24b-a2954da25e44"
      },
      "source": [
        "predictor.load_state_dict(inference_file['model_state_dict']) #模型加载训练好的参数\n",
        "print(predictor)"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentClassifier(\n",
            "  (bert_layer): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VghN2sOsuTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#与数据处理类一样\n",
        "def preprocess(sentence, maxlen=64):\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "\n",
        "    tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "\n",
        "    if len(tokens) < maxlen:\n",
        "\n",
        "        tokens = tokens + ['[PAD]' for _ in range(maxlen - len(tokens))]\n",
        "    else:\n",
        "\n",
        "        tokens = tokens[:maxlen-1] + ['[SEP]']\n",
        "    \n",
        "    tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    \n",
        "    tokens_ids_tensor = torch.tensor(tokens_ids).unsqueeze(0)\n",
        "\n",
        "    attn_mask = (tokens_ids_tensor != 0).long()\n",
        "\n",
        "    return tokens_ids_tensor, attn_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MLfqFn4VDbL",
        "colab_type": "text"
      },
      "source": [
        "做预测"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvmTze2cuQgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(net, iseq, masks):\n",
        "\n",
        "    device = 'cpu'\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    iseq, masks = iseq.to(device), masks.to(device)\n",
        "\n",
        "    p_logit = net(iseq, masks)    #[32,1]\n",
        "\n",
        "    probs = torch.sigmoid(p_logit.unsqueeze(-1))  #进行非线性激活得到一个概率值  \n",
        "\n",
        "    print(probs.size())       # [1,1,1] batch_size、sequence_length、divimension \n",
        "            \n",
        "    preds = (probs > 0.5).long().squeeze(0)     #得到标签\n",
        "\n",
        "    print(preds.size())               # [1,1]\n",
        "\n",
        "   \n",
        "    return preds, probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grUcqxrBwRU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_tokens, test_attn = preprocess(\"I pretty like this beautiful dress\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihWa4r5vixT-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "56b510ce-732d-4d3a-ffff-fee9d10d1626"
      },
      "source": [
        "print(test_tokens)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 101, 1045, 3492, 2066, 2023, 3376, 4377,  102,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHPsruzoi8XH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8544a5d6-eeb3-40c7-f692-68673374bf79"
      },
      "source": [
        "print(test_attn)"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XcSdRXuw1qf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ec6c1118-2b44-4c09-b8ca-0504bdb31a9b"
      },
      "source": [
        "preds, probs = predict(predictor,test_tokens,test_attn)\n",
        "print(preds,probs)"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 1])\n",
            "torch.Size([1, 1])\n",
            "tensor([[1]]) tensor([[[0.8649]]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqw5em7oxhjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}